#!/usr/bin/env python3
"""
4ê°œ GPUë¡œ ëª¨ë“  Baseline ë³‘ë ¬ ì‹¤í–‰ (ë™ì  ìŠ¤ì¼€ì¤„ë§)
- 5ê°œ ë°ì´í„°ì…‹ Ã— 3ê°œ Baseline = 15ê°œ ì‘ì—…
- GPU 4ê°œì— ë™ì ìœ¼ë¡œ í• ë‹¹
- ê°€ì¥ ë¹ ë¥¸ ì‹¤í–‰ì„ ìœ„í•œ ìµœì í™”
"""

import subprocess
import threading
import queue
import time
from datetime import datetime
from pathlib import Path

# ì‹¤í—˜ ì •ì˜
DATASETS = ["aras", "casas", "doore", "openpack", "opportunity"]
BASELINES = ["calimera", "earliest", "stopandhop"]

# ì‘ì—… ìƒì„± (ìš°ì„ ìˆœìœ„: ë¹ ë¥¸ ì‘ì—… ë¨¼ì €)
def create_tasks():
    """ì‘ì—… ìš°ì„ ìˆœìœ„ ì„¤ì • (ë¹ ë¥¸ ê²ƒ ë¨¼ì €)"""
    tasks = []
    
    # Priority 1: EARLIEST (ê°€ì¥ ë¹ ë¦„)
    for dataset in DATASETS:
        tasks.append(("earliest", dataset, 1))
    
    # Priority 2: CALIMERA (ì¤‘ê°„)
    for dataset in DATASETS:
        tasks.append(("calimera", dataset, 2))
    
    # Priority 3: Stop and Hop (ëŠë¦¼)
    for dataset in DATASETS:
        tasks.append(("stopandhop", dataset, 3))
    
    # ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬
    tasks.sort(key=lambda x: x[2])
    return tasks

def get_command(baseline, dataset):
    """ê° baselineë³„ ì‹¤í–‰ ëª…ë ¹ì–´ ìƒì„±"""
    base_dir = "/home/juice/EarlyHAR/EarlyHAR"
    conda_cmd = "source ~/miniconda3/etc/profile.d/conda.sh && conda activate pytorch-env && "
    conda_cmd += f"export NUMBA_CACHE_DIR={base_dir}/.numba_cache && "
    
    if baseline == "calimera":
        cmd = conda_cmd + f"python {base_dir}/main_cal.py "
        cmd += f"--dataset {dataset} --k_fold 5 --padding mean --augment True --aug_method noise --delay_penalty 1"
        
    elif baseline == "earliest":
        cmd = conda_cmd + f"python {base_dir}/main_earliest.py "
        cmd += f"--dataset {dataset} --k_fold 5 --padding mean --augment --aug_method noise "
        cmd += f"--epochs 50 --batch_size 32 --nhid 64 --patience 10"
        
    elif baseline == "stopandhop":
        cmd = conda_cmd + f"python {base_dir}/main_stopandhop.py "
        cmd += f"--dataset {dataset} --k_fold 5 --padding mean --augment --aug_method noise "
        cmd += f"--n_epochs 50 --batch_size 32 --nhid 64 --patience 10"
    
    return cmd

class GPUWorker(threading.Thread):
    """GPUë³„ ì‘ì—… ì²˜ë¦¬ ìŠ¤ë ˆë“œ"""
    
    def __init__(self, gpu_id, task_queue, results):
        super().__init__()
        self.gpu_id = gpu_id
        self.task_queue = task_queue
        self.results = results
        self.daemon = True
        
    def run(self):
        while True:
            try:
                baseline, dataset, priority = self.task_queue.get(timeout=1)
            except queue.Empty:
                break
                
            task_name = f"{baseline}_{dataset}"
            log_file = f"logs/{task_name}_gpu{self.gpu_id}.log"
            
            print(f"[GPU {self.gpu_id}] ğŸŸ¢ ì‹œì‘: {baseline.upper()} on {dataset}")
            start_time = time.time()
            
            # ëª…ë ¹ì–´ ì‹¤í–‰
            cmd = get_command(baseline, dataset)
            env = {"CUDA_VISIBLE_DEVICES": str(self.gpu_id)}
            
            try:
                with open(log_file, 'w') as f:
                    process = subprocess.run(
                        cmd,
                        shell=True,
                        executable='/bin/bash',
                        stdout=f,
                        stderr=subprocess.STDOUT,
                        env={**subprocess.os.environ.copy(), **env}
                    )
                
                elapsed = time.time() - start_time
                
                if process.returncode == 0:
                    status_emoji = "âœ…"
                    status_text = "ì™„ë£Œ"
                else:
                    status_emoji = "âŒ"
                    status_text = "ì‹¤íŒ¨"
                
                result = {
                    'gpu': self.gpu_id,
                    'baseline': baseline,
                    'dataset': dataset,
                    'status': 'success' if process.returncode == 0 else 'failed',
                    'elapsed': elapsed,
                    'log': log_file
                }
                
                self.results.append(result)
                
                print(f"[GPU {self.gpu_id}] {status_emoji} {status_text}: {baseline.upper()} on {dataset} ({elapsed/60:.1f}ë¶„)")
                
            except Exception as e:
                print(f"[GPU {self.gpu_id}] âŒ ì—ëŸ¬: {baseline} on {dataset} - {e}")
                self.results.append({
                    'gpu': self.gpu_id,
                    'baseline': baseline,
                    'dataset': dataset,
                    'status': 'error',
                    'error': str(e),
                    'log': log_file
                })
            
            self.task_queue.task_done()

def main():
    print("=" * 70)
    print("ğŸš€ 4ê°œ GPUë¡œ ì „ì²´ ì‹¤í—˜ ë³‘ë ¬ ì‹¤í–‰")
    print("=" * 70)
    print(f"ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    Path("logs").mkdir(exist_ok=True)
    
    # ì‘ì—… í ìƒì„±
    task_queue = queue.Queue()
    tasks = create_tasks()
    
    print(f"ğŸ“Š ì´ ì‘ì—… ìˆ˜: {len(tasks)}ê°œ")
    print(f"   - EARLIEST: {sum(1 for t in tasks if t[0]=='earliest')}ê°œ")
    print(f"   - CALIMERA: {sum(1 for t in tasks if t[0]=='calimera')}ê°œ")
    print(f"   - Stop & Hop: {sum(1 for t in tasks if t[0]=='stopandhop')}ê°œ")
    print()
    
    for task in tasks:
        task_queue.put(task)
    
    # GPU ì›Œì»¤ ì‹œì‘
    results = []
    workers = []
    
    print("ğŸ”§ GPU ì›Œì»¤ ì‹œì‘...")
    for gpu_id in range(4):  # GPU 0, 1, 2, 3
        worker = GPUWorker(gpu_id, task_queue, results)
        worker.start()
        workers.append(worker)
        print(f"   - GPU {gpu_id}: ì¤€ë¹„ ì™„ë£Œ")
    
    print()
    print("=" * 70)
    print("â³ ì‹¤í—˜ ì§„í–‰ ì¤‘... (Ctrl+Cë¡œ ì¤‘ë‹¨ ê°€ëŠ¥)")
    print("=" * 70)
    print()
    
    start_time = time.time()
    
    # ëª¨ë“  ì‘ì—… ì™„ë£Œ ëŒ€ê¸°
    task_queue.join()
    
    # ì›Œì»¤ ì¢…ë£Œ ëŒ€ê¸°
    for worker in workers:
        worker.join()
    
    total_elapsed = time.time() - start_time
    
    # ê²°ê³¼ ì¶œë ¥
    print()
    print("=" * 70)
    print("âœ… ì „ì²´ ì‹¤í—˜ ì™„ë£Œ!")
    print("=" * 70)
    print(f"ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ì´ ì†Œìš” ì‹œê°„: {total_elapsed/3600:.2f}ì‹œê°„ ({total_elapsed/60:.1f}ë¶„)")
    print()
    
    # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
    success = sum(1 for r in results if r['status'] == 'success')
    failed = len(results) - success
    
    print(f"ğŸ“Š ì‹¤í—˜ ê²°ê³¼:")
    print(f"   - ì„±ê³µ: {success}ê°œ")
    print(f"   - ì‹¤íŒ¨: {failed}ê°œ")
    print(f"   - ì´: {len(results)}ê°œ")
    print()
    
    # Baselineë³„ í†µê³„
    print("ğŸ“ˆ Baselineë³„ í‰ê·  ì‹œê°„:")
    for baseline in BASELINES:
        baseline_results = [r for r in results if r['baseline'] == baseline and r['status'] == 'success']
        if baseline_results:
            avg_time = sum(r['elapsed'] for r in baseline_results) / len(baseline_results)
            print(f"   - {baseline.upper()}: {avg_time/60:.1f}ë¶„")
    print()
    
    # GPUë³„ í†µê³„
    print("ğŸ–¥ï¸  GPUë³„ ì²˜ë¦¬ ì‘ì—…:")
    for gpu_id in range(4):
        gpu_results = [r for r in results if r['gpu'] == gpu_id]
        print(f"   - GPU {gpu_id}: {len(gpu_results)}ê°œ ì‘ì—…")
    print()
    
    # ì‹¤íŒ¨í•œ ì‘ì—… ì¶œë ¥
    if failed > 0:
        print("âŒ ì‹¤íŒ¨í•œ ì‘ì—…:")
        for r in results:
            if r['status'] != 'success':
                print(f"   - {r['baseline']} on {r['dataset']} (GPU {r['gpu']})")
                print(f"     ë¡œê·¸: {r['log']}")
        print()
    
    print("ğŸ“ ê²°ê³¼ ìœ„ì¹˜:")
    for dataset in DATASETS:
        print(f"   - results/{dataset}/")
    print()
    print("ğŸ“Š ê²°ê³¼ ìˆ˜ì§‘ ëª…ë ¹:")
    print("   python collect_results.py")
    print()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\n\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
