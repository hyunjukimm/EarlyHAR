#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ì¶”ë¡  ì‹œê°„ ë²¤ì¹˜ë§ˆí¬
"""

import time
import torch
import pickle
import numpy as np
import sys

# ë°ì´í„° ë¡œë“œ
print("="*80)
print("ê°„ë‹¨í•œ ì¶”ë¡  ì‹œê°„ ë²¤ì¹˜ë§ˆí¬")
print("="*80)

dataset = sys.argv[1] if len(sys.argv) > 1 else 'doore'
fold_idx = int(sys.argv[2]) if len(sys.argv) > 2 else 0

print(f"Dataset: {dataset}")
print(f"Fold: {fold_idx}")

# ë°ì´í„° ë¡œë“œ
fold_path = f'fold_data/{dataset}/fold_{fold_idx}.pkl'
print(f"\në°ì´í„° ë¡œë“œ: {fold_path}")

with open(fold_path, 'rb') as f:
    fold_data = pickle.load(f)

test_data = fold_data['test_data'][:10]  # 10ê°œë§Œ í…ŒìŠ¤íŠ¸
test_labels = fold_data['test_labels'][:10]

print(f"í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(test_data)}ê°œ")

# ë²¤ì¹˜ë§ˆí¬ í•¨ìˆ˜
def benchmark_model(model_name, forward_func, test_data, warmup=3):
    print(f"\n{'='*80}")
    print(f"{model_name} ë²¤ì¹˜ë§ˆí¬")
    print(f"{'='*80}")
    
    # Warmup
    print(f"Warmup ({warmup}íšŒ)...")
    for _ in range(warmup):
        try:
            _ = forward_func(test_data[0])
        except:
            pass
    
    # ì¸¡ì •
    print(f"ì¸¡ì • ì¤‘ ({len(test_data)}ê°œ ìƒ˜í”Œ)...")
    times = []
    
    for i, sample in enumerate(test_data):
        start = time.perf_counter()
        try:
            _ = forward_func(sample)
            end = time.perf_counter()
            times.append((end - start) * 1000)
        except Exception as e:
            print(f"  ìƒ˜í”Œ {i} ì—ëŸ¬: {e}")
            continue
    
    if times:
        mean_time = np.mean(times)
        std_time = np.std(times)
        median_time = np.median(times)
        
        print(f"\nê²°ê³¼:")
        print(f"  í‰ê·  ì¶”ë¡  ì‹œê°„: {mean_time:.2f} ms")
        print(f"  í‘œì¤€í¸ì°¨:      {std_time:.2f} ms")
        print(f"  ì¤‘ì•™ê°’:        {median_time:.2f} ms")
        print(f"  ì²˜ë¦¬ëŸ‰:        {1000/mean_time:.2f} samples/s")
        
        return mean_time
    else:
        print("ì¸¡ì • ì‹¤íŒ¨!")
        return None

# CALIMERA í…ŒìŠ¤íŠ¸
try:
    from baselines.calimera import CALIMERA
    from data_preprocessing.data_preprocess import pad_sequences
    
    print("\n" + "="*80)
    print("CALIMERA ì¤€ë¹„ ì¤‘...")
    print("="*80)
    
    # ê°„ë‹¨í•œ í•™ìŠµ
    train_tensor, _ = pad_sequences(test_data[:5], padding_type='mean')
    X_train = train_tensor.permute(0, 2, 1).numpy()
    y_train = test_labels[:5].numpy() if torch.is_tensor(test_labels) else np.array(test_labels[:5])
    
    model_cal = CALIMERA(delay_penalty=1)
    model_cal.fit(X_train, y_train)
    
    def calimera_forward(sample):
        tensor, _ = pad_sequences([sample], padding_type='mean')
        X = tensor.permute(0, 2, 1).numpy()
        return model_cal.test(X)
    
    cal_time = benchmark_model("CALIMERA", calimera_forward, test_data[5:], warmup=2)
    
except Exception as e:
    print(f"\nâš ï¸  CALIMERA ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
    cal_time = None

# EARLIEST í…ŒìŠ¤íŠ¸
try:
    from baselines.EARLIEST.model import EARLIEST
    
    print("\n" + "="*80)
    print("EARLIEST ì¤€ë¹„ ì¤‘...")
    print("="*80)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    test_tensor, _ = pad_sequences(test_data, padding_type='mean')
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    input_channels = test_tensor.shape[2]
    num_classes = len(torch.unique(test_labels))
    
    model_earliest = EARLIEST(
        ninp=input_channels,
        nhid=64,
        rnn_cell='LSTM',
        nlayers=1,
        nclasses=num_classes,
        lam=0.0
    ).to(device)
    model_earliest.eval()
    
    def earliest_forward(sample):
        tensor, _ = pad_sequences([sample], padding_type='mean')
        tensor = tensor.to(device)
        X = tensor.permute(1, 0, 2)  # (T, 1, V)
        with torch.no_grad():
            return model_earliest(X, test=True)
    
    ear_time = benchmark_model("EARLIEST", earliest_forward, test_data, warmup=2)
    
except Exception as e:
    print(f"\nâš ï¸  EARLIEST ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
    ear_time = None

# Stop and Hop í…ŒìŠ¤íŠ¸
try:
    from baselines.StopAndHop.model import StopAndHop
    
    print("\n" + "="*80)
    print("Stop and Hop ì¤€ë¹„ ì¤‘...")
    print("="*80)
    
    config = {
        'n_epochs': 50,
        'nhid': 64,
        'rnn_cell': 'LSTM',
        'nlayers': 1,
    }
    
    model_sh = StopAndHop(
        ninp=input_channels,
        nclasses=num_classes,
        config=config,
        std=0.1,
        lam=0.0
    ).to(device)
    model_sh.eval()
    
    def stopandhop_forward(sample):
        tensor, _ = pad_sequences([sample], padding_type='mean')
        X = tensor.numpy()
        with torch.no_grad():
            return model_sh(X, test=True)
    
    sh_time = benchmark_model("Stop and Hop", stopandhop_forward, test_data, warmup=2)
    
except Exception as e:
    print(f"\nâš ï¸  Stop and Hop ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
    sh_time = None

# ìµœì¢… ë¹„êµ
print("\n" + "="*80)
print("ìµœì¢… ë¹„êµ")
print("="*80)

results = []
if cal_time:
    results.append(("CALIMERA", cal_time))
if ear_time:
    results.append(("EARLIEST", ear_time))
if sh_time:
    results.append(("Stop and Hop", sh_time))

if results:
    results.sort(key=lambda x: x[1])
    
    print(f"\n{'ìˆœìœ„':<5} {'Baseline':<15} {'ì¶”ë¡  ì‹œê°„':<15} {'ì²˜ë¦¬ëŸ‰':<15}")
    print("-" * 55)
    
    for i, (name, time_ms) in enumerate(results, 1):
        throughput = 1000 / time_ms
        emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
        print(f"{emoji} {i:<3} {name:<15} {time_ms:>10.2f} ms {throughput:>10.2f} sps")
    
    print("\nğŸ’¡ í•´ì„:")
    print(f"  - ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸: {results[0][0]} ({results[0][1]:.2f} ms)")
    print(f"  - ê°€ì¥ ëŠë¦° ëª¨ë¸: {results[-1][0]} ({results[-1][1]:.2f} ms)")
    print(f"  - ì†ë„ ì°¨ì´: {results[-1][1] / results[0][1]:.1f}ë°°")
else:
    print("âš ï¸  ì¸¡ì • ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

print()
